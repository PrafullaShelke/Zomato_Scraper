{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPER TO DOWNLOAD REVIEWS FROM ZOMATO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#IMPORTING ALL THE REQUIRED MODULES FOR THIS TASK\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#USER AGENT HEADERS\n",
    "headers={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}\n",
    "#SCRAPING DATA ONLY FROM INDIAN RESTAURENTS\n",
    "url=\"http://www.zomato.com/india\"\n",
    "#STORES LINKS\n",
    "links=[]\n",
    "eats=[\"lunch\",\"breakfast\",\"dinner\",\"delivery\"]\n",
    "#First write links to it.\n",
    "f=open(\"hotellinks.txt\",\"w\")\n",
    "#open the above file in read mode after getting all the hotel links\n",
    "#f=open(\"hotellinks.txt\",\"r\")\n",
    "#hotels=f.readlines()\n",
    "hotels=[]\n",
    "#uncomment these while scraping reviews\n",
    "#for hotel in f.readlines():\n",
    "#    hotels.append(hotel.strip(\"\\n\"))  \n",
    "def get_links():\n",
    "    temp=[]\n",
    "    r=requests.get(url,headers=headers)\n",
    "    bs=BeautifulSoup(r.content,\"lxml\")\n",
    "    for href in bs.find_all(\"div\",class_=\"ui segment\"):\n",
    "        temp.append(href.find_all('a')[0]['href'].strip(\"\"))\n",
    "    for i in range(5):\n",
    "        for link in temp:\n",
    "            if re.search(r'/$',link):\n",
    "                temp.remove(link)\n",
    "    for link in temp:\n",
    "        for eat in eats:\n",
    "            links.append(link+\"/\"+eat)\n",
    "def get_hotels():\n",
    "    for link in links:\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            r=requests.get(link,headers=headers)\n",
    "        except:\n",
    "            pass\n",
    "        bs=BeautifulSoup(r.content,\"lxml\")\n",
    "        for link in bs.find_all(\"a\",{\"data-result-type\":\"ResCard_Name\"}):\n",
    "            f.write(link['href'])\n",
    "            f.write(\"\\n\")\n",
    "            hotels.append(link['href'])\n",
    "\n",
    "def get_reviews():\n",
    "    reviews_dict={\"Reviews\":[],\"Rating\":[],\"label\":[],\"hotel\":[]}\n",
    "    sleeptime=0\n",
    "    for hotel in hotels:\n",
    "        time.sleep(1)\n",
    "        sleeptime=sleeptime+1\n",
    "        try:\n",
    "            r=requests.get(hotel,headers=headers)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "        bs=BeautifulSoup(r.content,\"lxml\")\n",
    "        for text in bs.find_all(\"div\",{\"itemprop\":\"description\"}):\n",
    "            print(hotel)\n",
    "            if(hotel.count(\"/\")==3):\n",
    "                reviews_dict[\"hotel\"].append(hotel.split(\"/\")[3])\n",
    "            else:\n",
    "                 reviews_dict[\"hotel\"].append(hotel.split(\"/\")[4])   \n",
    "            reviews_dict[\"Reviews\"].append(text.text.splitlines()[2].strip(\" \"))\n",
    "            reviews_dict[\"Rating\"].append(text.find(\"div\")['aria-label'].strip(\"Rated\"))\n",
    "            reviews_dict[\"label\"].append(text.find(\"div\")['title'])\n",
    "            #print(text.text,text.find(\"div\")['title'],text.find(\"div\")['aria-label'].strip(\"Rated\").strip(\" \"))\n",
    "        if(sleeptime%1000==0):\n",
    "            time.sleep(5)\n",
    "        data= pd.DataFrame.from_dict(reviews_dict)\n",
    "        data.to_csv(\"data2.csv\",headers=False)\n",
    "#Uncomment these lines to work your way through scraping    \n",
    "#get_links()\n",
    "#get_hotels()\n",
    "#get_reviews()\n",
    "#print(hotels[2426])\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for getting more reviews through XHR requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "def more_reviews():\n",
    "    s=requests.session()\n",
    "    headers={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}\n",
    "    for i,hotel in enumerate(hotels):\n",
    "        print(hotel)\n",
    "        try:\n",
    "            r=s.get(hotel,headers=headers)\n",
    "        except:\n",
    "            pass\n",
    "        b=BeautifulSoup(r.content,\"lxml\")\n",
    "        if b.find(\"span\",class_=\"zs-load-more-count\"):\n",
    "            total=int(b.find(\"span\",class_=\"zs-load-more-count\").text)\n",
    "            #print(r.content)\n",
    "            #print(b.find_all(\"div\",class_=\"ui segment clearfix zs-load-more res-page-load-more\")[0][\"data-entity_id\"])\n",
    "            my_cookie={\"__jpuri\":hotel}\n",
    "            headers={'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36',\n",
    "                    \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "                     \"Referer\":\"https://www.zomato.com/\"\n",
    "                    }\n",
    "            requests.utils.add_dict_to_cookiejar(s.cookies, my_cookie)\n",
    "            for number in range(2,total):\n",
    "                payload={\"entity_id\":b.find_all(\"div\",class_=\"ui segment clearfix zs-load-more res-page-load-more\")[0][\"data-entity_id\"],\n",
    "                          \"limit\":\"5\",\n",
    "                          \"page\":number,\n",
    "                          \"profile_action\":\"reviews-top\"}\n",
    "                try:\n",
    "                    req=s.post(\"https://www.zomato.com/php/social_load_more.php\",headers=headers,data=payload)\n",
    "                except:\n",
    "                    pass\n",
    "                j=json.loads(req.content.decode(\"utf-8\").strip(\"\\n\"))\n",
    "                html=j['html'].strip(\"\\n\")\n",
    "                bs=BeautifulSoup(html,\"lxml\")\n",
    "                #print(bs.find_all(\"div\",{\"itemprop\":\"description\"}))\n",
    "                for text in bs.find_all(\"div\",{\"itemprop\":\"description\"}):\n",
    "                    if(hotel.count(\"/\")==3):\n",
    "                        reviews_dict[\"hotel\"].append(hotel.split(\"/\")[3])\n",
    "                    else:\n",
    "                        reviews_dict[\"hotel\"].append(hotel.split(\"/\")[4])  \n",
    "                    reviews_dict[\"Reviews\"].append(text.text.splitlines()[2].strip(\" \"))\n",
    "                    reviews_dict[\"Rating\"].append(text.find(\"div\")['aria-label'].strip(\"Rated\"))\n",
    "                    reviews_dict[\"label\"].append(text.find(\"div\")['title'])\n",
    "                    #print(text.text,text.find(\"div\")['title'],text.find(\"div\")['aria-label'].strip(\"Rated\").strip(\" \"))\n",
    "            data= pd.DataFrame.from_dict(reviews_dict)\n",
    "            #print(\"something\")\n",
    "            data.to_csv(\"data.csv\",headers=False)\n",
    "f=open(\"hotellinks.txt\",\"r\")\n",
    "hotels=[]\n",
    "reviews_dict={\"Reviews\":[],\"Rating\":[],\"label\":[],\"hotel\":[]}\n",
    "for h in f.readlines():\n",
    "    hotels.append(h.strip(\"\\n\"))\n",
    "#uncomment below line \n",
    "#more_reviews()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
